#!/usr/bin/env python3
"""
EfficientDet-Lite0 æ£šæœ­æ¤œå‡ºãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import tensorflow as tf
import numpy as np
import os
import json
from pathlib import Path
import matplotlib.pyplot as plt
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

def load_coco_annotations(annotation_path):
    """COCOå½¢å¼ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    with open(annotation_path, 'r', encoding='utf-8') as f:
        annotations = json.load(f)
    return annotations

def create_efficientdet_lite0_model(num_classes, img_size=(512, 512)):
    """EfficientDet-Lite0ãƒ™ãƒ¼ã‚¹ã®æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
    # EfficientNetB0ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨
    base_model = EfficientNetB0(
        weights='imagenet',
        include_top=False,
        input_shape=(*img_size, 3)
    )
    
    # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’å‡çµ
    base_model.trainable = False
    
    # æ¤œå‡ºãƒ˜ãƒƒãƒ‰ã‚’è¿½åŠ 
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.3)(x)
    
    # å„ã‚¯ãƒ©ã‚¹ã®æ¤œå‡ºå‡ºåŠ›
    outputs = []
    for i in range(num_classes):
        class_output = Dense(4, name=f'bbox_{i}')(x)  # x, y, w, h
        confidence_output = Dense(1, activation='sigmoid', name=f'confidence_{i}')(x)
        outputs.extend([class_output, confidence_output])
    
    model = Model(inputs=base_model.input, outputs=outputs)
    return model

def create_data_generator(annotations, img_dir, batch_size=8, img_size=(512, 512)):
    """ãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆ"""
    def generator():
        while True:
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠ
            batch_indices = np.random.choice(len(annotations['images']), batch_size)
            
            batch_images = []
            batch_targets = []
            
            for idx in batch_indices:
                img_info = annotations['images'][idx]
                img_path = Path(img_dir) / img_info['file_name']
                
                if not img_path.exists():
                    continue
                
                # ç”»åƒèª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†
                img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)
                img_array = tf.keras.preprocessing.image.img_to_array(img)
                img_array = img_array / 255.0
                
                # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—
                img_annotations = [ann for ann in annotations['annotations'] if ann['image_id'] == img_info['id']]
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
                targets = []
                for class_id in range(len(annotations['categories'])):
                    class_annotations = [ann for ann in img_annotations if ann['category_id'] == class_id]
                    
                    if class_annotations:
                        # æœ€åˆã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨
                        bbox = class_annotations[0]['bbox']
                        # æ­£è¦åŒ–
                        bbox = [bbox[0]/img_size[0], bbox[1]/img_size[1], 
                               bbox[2]/img_size[0], bbox[3]/img_size[1]]
                        confidence = 1.0
                    else:
                        bbox = [0, 0, 0, 0]
                        confidence = 0.0
                    
                    targets.extend(bbox + [confidence])
                
                batch_images.append(img_array)
                batch_targets.append(targets)
            
            if batch_images:
                yield np.array(batch_images), np.array(batch_targets)
    
    return generator

def train_model(model, train_generator, val_generator, epochs=100):
    """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            min_lr=1e-7
        ),
        ModelCheckpoint(
            'best_shelf_detector.h5',
            monitor='val_loss',
            save_best_only=True,
            verbose=1
        )
    ]
    
    # ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
    model.compile(
        optimizer=Adam(learning_rate=1e-4),
        loss='mse',
        metrics=['mae']
    )
    
    # è¨“ç·´å®Ÿè¡Œ
    history = model.fit(
        train_generator,
        validation_data=val_generator,
        epochs=epochs,
        callbacks=callbacks,
        verbose=1,
        steps_per_epoch=50,
        validation_steps=10
    )
    
    return history, model

def convert_to_tflite(model, output_path):
    """ãƒ¢ãƒ‡ãƒ«ã‚’TensorFlow Liteå½¢å¼ã«å¤‰æ›"""
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float16]
    
    tflite_model = converter.convert()
    
    with open(output_path, 'wb') as f:
        f.write(tflite_model)
    
    print(f"âœ… TensorFlow Liteãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")

def main():
    dataset_path = Path("shelf_tag_dataset")
    
    # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    train_annotations = load_coco_annotations(dataset_path / "annotations" / "train_annotations.json")
    val_annotations = load_coco_annotations(dataset_path / "annotations" / "val_annotations.json")
    
    num_classes = len(train_annotations['categories'])
    print(f"ğŸ¯ æ¤œå‡ºã‚¯ãƒ©ã‚¹æ•°: {num_classes}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ä½œæˆ
    train_generator = create_data_generator(
        train_annotations, 
        dataset_path / "train",
        batch_size=8
    )
    val_generator = create_data_generator(
        val_annotations,
        dataset_path / "validation", 
        batch_size=8
    )
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    model = create_efficientdet_lite0_model(num_classes)
    print("âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    # è¨“ç·´å®Ÿè¡Œ
    print("ğŸš€ è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™...")
    history, trained_model = train_model(model, train_generator, val_generator)
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    trained_model.save('shelf_detector_model.h5')
    print("âœ… è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    
    # TensorFlow Liteå¤‰æ›
    convert_to_tflite(trained_model, 'shelf_detector_model.tflite')
    
    # è¨“ç·´å±¥æ­´ãƒ—ãƒ­ãƒƒãƒˆ
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='è¨“ç·´æå¤±')
    plt.plot(history.history['val_loss'], label='æ¤œè¨¼æå¤±')
    plt.title('ãƒ¢ãƒ‡ãƒ«æå¤±')
    plt.xlabel('ã‚¨ãƒãƒƒã‚¯')
    plt.ylabel('æå¤±')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history.history['mae'], label='è¨“ç·´MAE')
    plt.plot(history.history['val_mae'], label='æ¤œè¨¼MAE')
    plt.title('å¹³å‡çµ¶å¯¾èª¤å·®')
    plt.xlabel('ã‚¨ãƒãƒƒã‚¯')
    plt.ylabel('MAE')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

if __name__ == "__main__":
    main()
